# 爬虫配置文件
# 管理所有需要爬取的学校官网

universities:
  - name: "北京理工大学自动化学院"
    url: "https://ac.bit.edu.cn/szdw/dsmd/bssds/index.htm"
    scraper_type: "two_level"  # 两层结构：列表页 + 详情页
    enabled: true
    update_frequency: "weekly"  # daily/weekly/monthly

    # 列表页配置
    list_page:
      container_selector: "ul.list01.list002 > li"  # 导师列表容器（注意：页面有2个这样的列表）
      link_selector: "a"                             # 导师详情页链接
      name_selector: "a"                             # 导师姓名

    # 详情页配置（优先级从高到低尝试）
    detail_page:
      title:
        - keywords: ["职称", "Title"]
          extract_method: "next_sibling_text"
        - pattern: "(教授|副教授|研究员|讲师)"
        - selector: "span.title, .职称, .title"

      research_areas:
        - keywords: ["研究方向", "研究领域", "Research Interests", "研究兴趣"]
          extract_method: "parent_text"
        - selector_all: "p:has(strong:contains('研究方向')) ~ ul li, p:contains('研究方向') ~ ul li"
        - selector_all: "ul li:contains('研究'), ol li:contains('研究')"
        - pattern: true
          keywords: ["研究方向", "研究领域"]
        - selector: ".research, .研究方向"

      office:
        - keywords: ["办公室", "Office", "办公地点"]
          extract_method: "next_sibling_text"

      department:
        - keywords: ["所在单位", "单位", "学院"]
          extract_method: "next_sibling_text"

      education_background:
        - keywords: ["教育背景", "学历", "Education"]
          extract_method: "parent_text"

  # 华北电力大学电气与电子工程学院
  - name: "华北电力大学电气与电子工程学院"
    url: "https://electric.ncepu.edu.cn/szdw/xyjj6/index.htm"
    scraper_type: "two_level"
    enabled: true
    update_frequency: "weekly"

    list_page:
      container_selector: "ul.subLightYearsList li"  # 精确定位导师列表
      link_selector: "a"
      name_selector: "p"  # 姓名在p标签内

    detail_page:
      title:
        - keywords: ["职称", "Title"]
          extract_method: "next_sibling_text"
        - pattern: "(教授|副教授|研究员|讲师)"

      research_areas:
        - keywords: ["研究方向", "Focus Area", "研究领域"]
          extract_method: "parent_text"
        - pattern: true
          keywords: ["研究方向", "Focus Area"]
        # 提取"Ø"符号标记的研究方向列表
        - selector_all: "p:contains('研究方向') ~ p, p:contains('Focus Area') ~ p"
        - selector_all: "p:contains('研究方向') ~ ul li, p:contains('Focus Area') ~ ul li"
        - selector_all: "ul li:contains('研究'), ol li:contains('研究')"

      office:
        - keywords: ["办公地址", "办公室", "Office"]
          extract_method: "next_sibling_text"

      department:
        - keywords: ["所在单位", "单位"]
          extract_method: "next_sibling_text"

  # 北京航空航天大学自动化科学与电气工程学院
  - name: "北京航空航天大学自动化科学与电气工程学院"
    url: "https://dept3.buaa.edu.cn/szjs/yjsds/bssds.htm"
    scraper_type: "two_level"
    enabled: true
    update_frequency: "weekly"

    list_page:
      container_selector: "div.sz_js_nr li"
      link_selector: "a"
      name_selector: "a"

    detail_page:
      title:
        - keywords: ["职称", "职务"]
          extract_method: "next_sibling_text"
        - pattern: "(教授|副教授|研究员|讲师|博士生导师)"
        - selector: ".teacher_title, .title"

      research_areas:
        - keywords: ["研究方向", "研究领域", "研究兴趣", "Research Interests"]
          extract_method: "parent_text"
        - pattern: true
          keywords: ["研究方向", "研究领域"]
        # 从个人简介中提取研究关键词
        - selector: ".profile_content, .introduction"
        - selector_all: "p:contains('研究方向') ~ ul li, p:contains('Research Interests') ~ ul li"
        - selector_all: "ul li:contains('研究'), ol li:contains('Research')"

      office:
        - keywords: ["办公地点", "办公室", "Office"]
          extract_method: "next_sibling_text"

      department:
        - keywords: ["所在单位", "单位", "学科"]
          extract_method: "next_sibling_text"

  # 更多学校可以在这里添加
  # - name: "清华大学计算机系"
  #   url: "https://www.cs.tsinghua.edu.cn/..."
  #   scraper_type: "two_level"
  #   ...

# 爬虫全局配置
settings:
  request_delay: 1.0           # 请求间隔（秒）
  timeout: 30                  # 请求超时（秒）
  max_retries: 3               # 最大重试次数
  user_agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
  respect_robots_txt: true     # 遵守 robots.txt
  max_workers: 3               # 并发爬取数量
